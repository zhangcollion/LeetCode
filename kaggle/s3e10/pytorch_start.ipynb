{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-18T09:07:42.860522Z","iopub.execute_input":"2023-03-18T09:07:42.861629Z","iopub.status.idle":"2023-03-18T09:07:42.881596Z","shell.execute_reply.started":"2023-03-18T09:07:42.861585Z","shell.execute_reply":"2023-03-18T09:07:42.880217Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/pulsar-classification-for-class-prediction/Pulsar.csv\n/kaggle/input/playground-series-s3e10/sample_submission.csv\n/kaggle/input/playground-series-s3e10/train.csv\n/kaggle/input/playground-series-s3e10/test.csv\n/kaggle/input/predicting-pulsar-starintermediate/pulsar_data_train.csv\n/kaggle/input/predicting-pulsar-starintermediate/pulsar_data_test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s3e10/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s3e10/test.csv')\nback_train = pd.read_csv('/kaggle/input/pulsar-classification-for-class-prediction/Pulsar.csv')\nback_train.head(2)\ndf_train['is_generated'] = 1\ndf_test['is_generated'] = 1\nback_train['is_generated'] = 0\nback_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T09:07:48.095808Z","iopub.execute_input":"2023-03-18T09:07:48.096218Z","iopub.status.idle":"2023-03-18T09:07:48.769406Z","shell.execute_reply.started":"2023-03-18T09:07:48.096179Z","shell.execute_reply":"2023-03-18T09:07:48.768195Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Mean_Integrated         SD        EK  Skewness  Mean_DMSNR_Curve  \\\n0       140.562500  55.683782 -0.234571 -0.699648          3.199833   \n1       102.507812  58.882430  0.465318 -0.515088          1.677258   \n\n   SD_DMSNR_Curve  EK_DMSNR_Curve  Skewness_DMSNR_Curve  Class  is_generated  \n0       19.110426        7.975532             74.242225      0             0  \n1       14.860146       10.576487            127.393580      0             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean_Integrated</th>\n      <th>SD</th>\n      <th>EK</th>\n      <th>Skewness</th>\n      <th>Mean_DMSNR_Curve</th>\n      <th>SD_DMSNR_Curve</th>\n      <th>EK_DMSNR_Curve</th>\n      <th>Skewness_DMSNR_Curve</th>\n      <th>Class</th>\n      <th>is_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140.562500</td>\n      <td>55.683782</td>\n      <td>-0.234571</td>\n      <td>-0.699648</td>\n      <td>3.199833</td>\n      <td>19.110426</td>\n      <td>7.975532</td>\n      <td>74.242225</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_outlier(train):\n    outliers = train[\n        (train['Class']==1)&\n        (train['Mean_Integrated']>115)&\n        (train['SD']>45)&\n        (train['EK']<0.03)&\n        (train['Skewness']<1)&\n        (train['Mean_DMSNR_Curve']<20)\n    ].index\n    train.drop(outliers,inplace=True)\n    train.reset_index()\n    return train\n","metadata":{"execution":{"iopub.status.busy":"2023-03-18T09:07:54.375390Z","iopub.execute_input":"2023-03-18T09:07:54.376828Z","iopub.status.idle":"2023-03-18T09:07:54.384828Z","shell.execute_reply.started":"2023-03-18T09:07:54.376775Z","shell.execute_reply":"2023-03-18T09:07:54.383503Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X = df_train.drop(columns=['id'])\ntrain_data = pd.concat([X, back_train],axis=0)\ntrain_data = remove_outlier(train_data)\nX = train_data.drop(columns=['Class'])\ny = train_data['Class']\ntest = df_test.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2023-03-18T09:07:57.011246Z","iopub.execute_input":"2023-03-18T09:07:57.011672Z","iopub.status.idle":"2023-03-18T09:07:57.098175Z","shell.execute_reply.started":"2023-03-18T09:07:57.011631Z","shell.execute_reply":"2023-03-18T09:07:57.096830Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def f_importance_plot(f_imp):\n    fig = plt.figure(figsize = (15, 0.35*len(f_imp)))\n    plt.title('Feature importances', size=25, y=1.05, \n              fontname='Calibri', fontweight='bold', color='#444444')\n    a = sns.barplot(data=f_imp, x='avg_imp', y='feature', \n                    palette='Blues_d', linestyle=\"-\", \n                    linewidth=1, edgecolor=\"black\")\n    plt.xlabel('')\n    plt.xticks([])\n    plt.ylabel('')\n    plt.yticks(size=11, color='#444444')\n    \n    for j in ['right', 'top', 'bottom']:\n        a.spines[j].set_visible(False)\n    for j in ['left']:\n        a.spines[j].set_linewidth(0.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-18T03:24:34.814647Z","iopub.execute_input":"2023-03-18T03:24:34.815048Z","iopub.status.idle":"2023-03-18T03:24:34.823541Z","shell.execute_reply.started":"2023-03-18T03:24:34.815012Z","shell.execute_reply":"2023-03-18T03:24:34.822405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import combinations\nfrom sklearn.preprocessing import StandardScaler\nclass Preprocessor:\n    def __init__(self, numeric_columns=None, max_pattern=2):\n        self.numeric_columns = numeric_columns\n        self.max_pattern = max_pattern\n        self.scaler = None\n        \n    def preprocess(self, X_train, X_test):\n        \n        X_train = self.create_numeric_combinations(X_train)\n        X_test = self.create_numeric_combinations(X_test)\n        \n        numeric_columns = [_ for _ in X_train.columns if X_train[_].dtype == 'float']\n        scaler = StandardScaler()\n        X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n        X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n\n        return X_train, X_test\n    \n    def create_numeric_combinations(self, df):\n        new_cols = []\n        for comb in range(2, len(self.numeric_columns) + 1):\n            for col in combinations(self.numeric_columns, comb):\n                if len(col) > self.max_pattern:\n                    break\n                col_names = list(col)\n                new_col = '_'.join(col_names) + '_mult'\n                df[new_col] = df[col_names[0]]\n                for c in col_names[1:]:\n                    df[new_col] *= df[c]\n                new_cols.append(new_col)\n\n        return df\n\nnumeric_columns = [_ for _ in test.columns if 'is_generated' not in _]\npp = Preprocessor(numeric_columns)\nX, test = pp.preprocess(X, test)\nprint(f\"X_train shape :{X.shape}\", f\"X_test shape :{test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-18T03:29:10.394924Z","iopub.execute_input":"2023-03-18T03:29:10.395371Z","iopub.status.idle":"2023-03-18T03:29:16.585018Z","shell.execute_reply.started":"2023-03-18T03:29:10.395334Z","shell.execute_reply":"2023-03-18T03:29:16.583889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.decomposition import PCA\nfrom umap import UMAP\nfrom sklearn.cluster import KMeans\nfrom haversine import haversine\n\nimport optuna\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import log_loss\n\nlgb_params = {\n    'max_depth': 9,\n    'learning_rate': 0.01,\n    'min_data_in_leaf': 36, \n    'num_leaves': 100, \n    'feature_fraction': 0.8, \n    'bagging_fraction': 0.89, \n    'bagging_freq': 5, \n    'lambda_l2': 28,\n    \n    'seed': 3407,\n    'objective': 'regression',\n    'boosting_type': 'gbdt',\n    'device': 'cpu', \n    'gpu_platform_id': 0,\n    'gpu_device_id': 0,\n    'n_jobs': -1,\n    'metric': 'rmse',\n    'verbose': -1\n}\n\nf_imp = pd.DataFrame({'feature': X.columns})\nFOLDS = 10\nseed = 3407\nbold = ['\\033[1m', '\\033[0m']\ntemp_pred = []\ntemp_y = []\nlogs = [] \ncv_scores = []\npredictions =[] \nk = KFold(n_splits=FOLDS, random_state=seed, shuffle=True)\nfor fold, (train_idx, val_idx) in enumerate(k.split(X, y)):\n    print(f'\\n--- FOLD {fold+1} ---')\n    model = lgb.LGBMClassifier(**lgb_params)\n    model = model.fit(X.iloc[train_idx],y.iloc[train_idx])\n    x_test,y_test = X.iloc[val_idx],y.iloc[val_idx]\n    fold_xt_pred = model.predict_proba(x_test)[:,1]\n    fold_test_pred = model.predict(test)\n    temp_pred.append(fold_xt_pred)\n    temp_y.append(y_test)\n    logs.append(log_loss(y_test,fold_xt_pred))\n    print(\"--------------\", log_loss(y_test,fold_xt_pred))\n    predictions.append(fold_test_pred)\n    cv_scores.append(np.mean(logs))\nlgbm_cv_score = np.mean(cv_scores)\nprint('LGBM CV SCORE : ', lgbm_cv_score)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:03:09.455320Z","iopub.execute_input":"2023-03-18T13:03:09.456284Z","iopub.status.idle":"2023-03-18T13:03:40.987169Z","shell.execute_reply.started":"2023-03-18T13:03:09.456233Z","shell.execute_reply":"2023-03-18T13:03:40.985094Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2868384055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m }\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mf_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mFOLDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3407\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"],"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error"}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-03-18T09:08:44.714188Z","iopub.execute_input":"2023-03-18T09:08:44.714625Z","iopub.status.idle":"2023-03-18T09:08:44.730172Z","shell.execute_reply.started":"2023-03-18T09:08:44.714583Z","shell.execute_reply":"2023-03-18T09:08:44.729021Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1]),\n array([0, 0, 0, ..., 0, 0, 1])]"},"metadata":{}}]},{"cell_type":"code","source":"ans_lgb = pd.read_csv(\"/kaggle/input/playground-series-s3e10/sample_submission.csv\")\nans_lgb[\"Class\"] = predictions #np.where(predictions>0.5, 1, 0)\nans_lgb.to_csv(\"ans_lgb.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T03:59:55.806575Z","iopub.execute_input":"2023-03-18T03:59:55.807292Z","iopub.status.idle":"2023-03-18T03:59:55.926988Z","shell.execute_reply.started":"2023-03-18T03:59:55.807251Z","shell.execute_reply":"2023-03-18T03:59:55.925888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-03-18T09:09:14.500977Z","iopub.execute_input":"2023-03-18T09:09:14.501375Z","iopub.status.idle":"2023-03-18T09:09:14.520621Z","shell.execute_reply.started":"2023-03-18T09:09:14.501340Z","shell.execute_reply":"2023-03-18T09:09:14.519389Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       Mean_Integrated         SD        EK  Skewness  Mean_DMSNR_Curve  \\\n0           140.046875  54.507800  0.058862 -0.567263          2.337793   \n1           107.828125  51.578965  0.284368 -0.338430          1.574415   \n2           135.062500  49.812343 -0.087784 -0.094341          3.576923   \n3           112.812500  41.926647  0.519921  1.287762          6.669732   \n4            96.210938  35.322620  0.481286  2.443080          2.218227   \n...                ...        ...       ...       ...               ...   \n78372       119.328125  46.449223  0.227636  0.161986          1.120401   \n78373       125.835938  43.986678  0.078460  0.077917          2.342809   \n78374       131.789062  43.493074  0.049140  0.402859          2.116221   \n78375        79.476562  42.579993  0.817383  1.818474          1.903010   \n78376        68.265625  39.611800  1.924393  5.348909         20.903010   \n\n       SD_DMSNR_Curve  EK_DMSNR_Curve  Skewness_DMSNR_Curve  is_generated  \n0           14.868335        9.591760            117.988781             1  \n1           12.501437       11.694968            182.704822             1  \n2           21.243336        7.252386             59.021499             1  \n3           29.013153        5.097661             27.105240             1  \n4           17.041064        9.766006            117.131775             1  \n...               ...             ...                   ...           ...  \n78372       13.883072       14.153556            213.485463             1  \n78373       13.008583        9.907167            136.815454             1  \n78374       14.639555       10.898768            147.929016             1  \n78375       15.844982       10.723755            143.273847             1  \n78376       55.143702        2.489474              5.413000             1  \n\n[78377 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean_Integrated</th>\n      <th>SD</th>\n      <th>EK</th>\n      <th>Skewness</th>\n      <th>Mean_DMSNR_Curve</th>\n      <th>SD_DMSNR_Curve</th>\n      <th>EK_DMSNR_Curve</th>\n      <th>Skewness_DMSNR_Curve</th>\n      <th>is_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140.046875</td>\n      <td>54.507800</td>\n      <td>0.058862</td>\n      <td>-0.567263</td>\n      <td>2.337793</td>\n      <td>14.868335</td>\n      <td>9.591760</td>\n      <td>117.988781</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>107.828125</td>\n      <td>51.578965</td>\n      <td>0.284368</td>\n      <td>-0.338430</td>\n      <td>1.574415</td>\n      <td>12.501437</td>\n      <td>11.694968</td>\n      <td>182.704822</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>135.062500</td>\n      <td>49.812343</td>\n      <td>-0.087784</td>\n      <td>-0.094341</td>\n      <td>3.576923</td>\n      <td>21.243336</td>\n      <td>7.252386</td>\n      <td>59.021499</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>112.812500</td>\n      <td>41.926647</td>\n      <td>0.519921</td>\n      <td>1.287762</td>\n      <td>6.669732</td>\n      <td>29.013153</td>\n      <td>5.097661</td>\n      <td>27.105240</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>96.210938</td>\n      <td>35.322620</td>\n      <td>0.481286</td>\n      <td>2.443080</td>\n      <td>2.218227</td>\n      <td>17.041064</td>\n      <td>9.766006</td>\n      <td>117.131775</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78372</th>\n      <td>119.328125</td>\n      <td>46.449223</td>\n      <td>0.227636</td>\n      <td>0.161986</td>\n      <td>1.120401</td>\n      <td>13.883072</td>\n      <td>14.153556</td>\n      <td>213.485463</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78373</th>\n      <td>125.835938</td>\n      <td>43.986678</td>\n      <td>0.078460</td>\n      <td>0.077917</td>\n      <td>2.342809</td>\n      <td>13.008583</td>\n      <td>9.907167</td>\n      <td>136.815454</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78374</th>\n      <td>131.789062</td>\n      <td>43.493074</td>\n      <td>0.049140</td>\n      <td>0.402859</td>\n      <td>2.116221</td>\n      <td>14.639555</td>\n      <td>10.898768</td>\n      <td>147.929016</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78375</th>\n      <td>79.476562</td>\n      <td>42.579993</td>\n      <td>0.817383</td>\n      <td>1.818474</td>\n      <td>1.903010</td>\n      <td>15.844982</td>\n      <td>10.723755</td>\n      <td>143.273847</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>78376</th>\n      <td>68.265625</td>\n      <td>39.611800</td>\n      <td>1.924393</td>\n      <td>5.348909</td>\n      <td>20.903010</td>\n      <td>55.143702</td>\n      <td>2.489474</td>\n      <td>5.413000</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>78377 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:12:11.059071Z","iopub.execute_input":"2023-03-18T13:12:11.059491Z","iopub.status.idle":"2023-03-18T13:12:11.065554Z","shell.execute_reply.started":"2023-03-18T13:12:11.059453Z","shell.execute_reply":"2023-03-18T13:12:11.064264Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Download training data from open datasets.\ntraining_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=True,\n    download=True,\n    transform=ToTensor(),\n)\n\n# Download test data from open datasets.\ntest_data = datasets.FashionMNIST(\n    root=\"data\",\n    train=False,\n    download=True,\n    transform=ToTensor(),\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:12:12.645306Z","iopub.execute_input":"2023-03-18T13:12:12.645702Z","iopub.status.idle":"2023-03-18T13:12:18.303658Z","shell.execute_reply.started":"2023-03-18T13:12:12.645668Z","shell.execute_reply":"2023-03-18T13:12:18.302265Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26421880 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef98214f11b40448bd81f0414dadb87"}},"metadata":{}},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/29515 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a873149898e645ddac498888a3704f45"}},"metadata":{}},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4422102 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59bd370577a24ac4b894891d6d4b5098"}},"metadata":{}},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5148 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c1419e409c4fef944356c3adf9bcae"}},"metadata":{}},{"name":"stdout","text":"Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 64\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size)\n\nfor X, y in test_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:13:24.125966Z","iopub.execute_input":"2023-03-18T13:13:24.127294Z","iopub.status.idle":"2023-03-18T13:13:24.189600Z","shell.execute_reply.started":"2023-03-18T13:13:24.127241Z","shell.execute_reply":"2023-03-18T13:13:24.188242Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\nShape of y: torch.Size([64]) torch.int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Creating Models","metadata":{}},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n             nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n    \n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.linear_relu_stack(x)\n        return x\n    \nmodel = NeuralNetwork().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:17:29.699121Z","iopub.execute_input":"2023-03-18T13:17:29.700331Z","iopub.status.idle":"2023-03-18T13:17:29.722328Z","shell.execute_reply.started":"2023-03-18T13:17:29.700284Z","shell.execute_reply":"2023-03-18T13:17:29.720912Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Using cpu device\nNeuralNetwork(\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear_relu_stack): Sequential(\n    (0): Linear(in_features=784, out_features=512, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=10, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:20:03.215086Z","iopub.execute_input":"2023-03-18T13:20:03.215528Z","iopub.status.idle":"2023-03-18T13:20:03.222397Z","shell.execute_reply.started":"2023-03-18T13:20:03.215484Z","shell.execute_reply":"2023-03-18T13:20:03.220855Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:19:22.413381Z","iopub.execute_input":"2023-03-18T13:19:22.413855Z","iopub.status.idle":"2023-03-18T13:19:22.422113Z","shell.execute_reply.started":"2023-03-18T13:19:22.413813Z","shell.execute_reply":"2023-03-18T13:19:22.420787Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:19:44.196658Z","iopub.execute_input":"2023-03-18T13:19:44.197128Z","iopub.status.idle":"2023-03-18T13:19:44.206256Z","shell.execute_reply.started":"2023-03-18T13:19:44.197085Z","shell.execute_reply":"2023-03-18T13:19:44.204585Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"epochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test(test_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:22:36.970784Z","iopub.execute_input":"2023-03-18T13:22:36.971761Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\nloss: 0.233197  [   64/60000]\nloss: 0.320735  [ 6464/60000]\nloss: 0.204201  [12864/60000]\nloss: 0.295273  [19264/60000]\nloss: 0.254464  [25664/60000]\nloss: 0.354950  [32064/60000]\nloss: 0.263224  [38464/60000]\nloss: 0.342192  [44864/60000]\nloss: 0.318746  [51264/60000]\nloss: 0.240935  [57664/60000]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.366559 \n\nEpoch 2\n-------------------------------\nloss: 0.233197  [   64/60000]\nloss: 0.320735  [ 6464/60000]\nloss: 0.204201  [12864/60000]\nloss: 0.295273  [19264/60000]\nloss: 0.254464  [25664/60000]\nloss: 0.354950  [32064/60000]\nloss: 0.263224  [38464/60000]\nloss: 0.342192  [44864/60000]\nloss: 0.318746  [51264/60000]\nloss: 0.240935  [57664/60000]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.366559 \n\nEpoch 3\n-------------------------------\nloss: 0.233197  [   64/60000]\nloss: 0.320735  [ 6464/60000]\nloss: 0.204201  [12864/60000]\nloss: 0.295273  [19264/60000]\nloss: 0.254464  [25664/60000]\nloss: 0.354950  [32064/60000]\nloss: 0.263224  [38464/60000]\nloss: 0.342192  [44864/60000]\nloss: 0.318746  [51264/60000]\nloss: 0.240935  [57664/60000]\nTest Error: \n Accuracy: 87.0%, Avg loss: 0.366559 \n\nEpoch 4\n-------------------------------\nloss: 0.233197  [   64/60000]\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model.pth\")\nprint(\"Saved PyTorch Model State to model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:22:17.702312Z","iopub.execute_input":"2023-03-18T13:22:17.702729Z","iopub.status.idle":"2023-03-18T13:22:17.715329Z","shell.execute_reply.started":"2023-03-18T13:22:17.702690Z","shell.execute_reply":"2023-03-18T13:22:17.713895Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Saved PyTorch Model State to model.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"model = NeuralNetwork()\nmodel.load_state_dict(torch.load(\"model.pth\"))","metadata":{"execution":{"iopub.status.busy":"2023-03-18T13:22:18.998181Z","iopub.execute_input":"2023-03-18T13:22:18.998621Z","iopub.status.idle":"2023-03-18T13:22:19.018119Z","shell.execute_reply.started":"2023-03-18T13:22:18.998582Z","shell.execute_reply":"2023-03-18T13:22:19.017051Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]}]}