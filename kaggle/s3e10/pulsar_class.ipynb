{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-18T07:41:55.637074Z","iopub.execute_input":"2023-03-18T07:41:55.637804Z","iopub.status.idle":"2023-03-18T07:41:55.674142Z","shell.execute_reply.started":"2023-03-18T07:41:55.637755Z","shell.execute_reply":"2023-03-18T07:41:55.672974Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/pulsar-classification-for-class-prediction/Pulsar.csv\n/kaggle/input/predicting-pulsar-starintermediate/pulsar_data_train.csv\n/kaggle/input/predicting-pulsar-starintermediate/pulsar_data_test.csv\n/kaggle/input/playground-series-s3e10/sample_submission.csv\n/kaggle/input/playground-series-s3e10/train.csv\n/kaggle/input/playground-series-s3e10/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/playground-series-s3e10/train.csv')\ndf_test = pd.read_csv('/kaggle/input/playground-series-s3e10/test.csv')\n# back_train = pd.read_csv('/kaggle/input/pulsar-classification-for-class-prediction/Pulsar.csv')\n# df_train['is_generated'] = 1\n# df_test['is_generated'] = 1\n# back_train['is_generated'] = 0\ndf_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:16:35.149336Z","iopub.execute_input":"2023-03-18T08:16:35.149747Z","iopub.status.idle":"2023-03-18T08:16:35.400047Z","shell.execute_reply.started":"2023-03-18T08:16:35.149713Z","shell.execute_reply":"2023-03-18T08:16:35.398814Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"   id  Mean_Integrated         SD        EK  Skewness  Mean_DMSNR_Curve  \\\n0   0       133.171875  59.716081  0.043133 -0.703383         54.917224   \n1   1        87.093750  36.257973  0.435469  2.266057          3.417224   \n\n   SD_DMSNR_Curve  EK_DMSNR_Curve  Skewness_DMSNR_Curve  Class  \n0       70.084438        0.749798             -0.649512      0  \n1       21.865069        7.039330             52.686251      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Mean_Integrated</th>\n      <th>SD</th>\n      <th>EK</th>\n      <th>Skewness</th>\n      <th>Mean_DMSNR_Curve</th>\n      <th>SD_DMSNR_Curve</th>\n      <th>EK_DMSNR_Curve</th>\n      <th>Skewness_DMSNR_Curve</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>133.171875</td>\n      <td>59.716081</td>\n      <td>0.043133</td>\n      <td>-0.703383</td>\n      <td>54.917224</td>\n      <td>70.084438</td>\n      <td>0.749798</td>\n      <td>-0.649512</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>87.093750</td>\n      <td>36.257973</td>\n      <td>0.435469</td>\n      <td>2.266057</td>\n      <td>3.417224</td>\n      <td>21.865069</td>\n      <td>7.039330</td>\n      <td>52.686251</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_outlier(train):\n    outliers = train[\n        (train['Class']==1)&\n        (train['Mean_Integrated']>115)&\n        (train['SD']>45)&\n        (train['EK']<0.03)&\n        (train['Skewness']<1)&\n        (train['Mean_DMSNR_Curve']<20)\n    ].index\n    train.drop(outliers,inplace=True)\n    train.reset_index()\n    return train\n","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:04:44.169605Z","iopub.execute_input":"2023-03-18T08:04:44.169992Z","iopub.status.idle":"2023-03-18T08:04:44.177120Z","shell.execute_reply.started":"2023-03-18T08:04:44.169960Z","shell.execute_reply":"2023-03-18T08:04:44.175760Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X = df_train.drop(columns=['id'])\n# train_data = pd.concat([X, back_train],axis=0)\ndf_train = remove_outlier(df_train)\nX = df_train.drop(columns=['id','Class'])\ny = df_train['Class']\ntest = df_test.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:16:46.631656Z","iopub.execute_input":"2023-03-18T08:16:46.632122Z","iopub.status.idle":"2023-03-18T08:16:46.660238Z","shell.execute_reply.started":"2023-03-18T08:16:46.632079Z","shell.execute_reply":"2023-03-18T08:16:46.659030Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def f_importance_plot(f_imp):\n    fig = plt.figure(figsize = (15, 0.35*len(f_imp)))\n    plt.title('Feature importances', size=25, y=1.05, \n              fontname='Calibri', fontweight='bold', color='#444444')\n    a = sns.barplot(data=f_imp, x='avg_imp', y='feature', \n                    palette='Blues_d', linestyle=\"-\", \n                    linewidth=1, edgecolor=\"black\")\n    plt.xlabel('')\n    plt.xticks([])\n    plt.ylabel('')\n    plt.yticks(size=11, color='#444444')\n    \n    for j in ['right', 'top', 'bottom']:\n        a.spines[j].set_visible(False)\n    for j in ['left']:\n        a.spines[j].set_linewidth(0.5)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-18T03:24:34.814647Z","iopub.execute_input":"2023-03-18T03:24:34.815048Z","iopub.status.idle":"2023-03-18T03:24:34.823541Z","shell.execute_reply.started":"2023-03-18T03:24:34.815012Z","shell.execute_reply":"2023-03-18T03:24:34.822405Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"from itertools import combinations\nfrom sklearn.preprocessing import StandardScaler\nclass Preprocessor:\n    def __init__(self, numeric_columns=None, max_pattern=2):\n        self.numeric_columns = numeric_columns\n        self.max_pattern = max_pattern\n        self.scaler = None\n        \n    def preprocess(self, X_train, X_test):\n        \n        X_train = self.create_numeric_combinations(X_train)\n        X_test = self.create_numeric_combinations(X_test)\n        \n        numeric_columns = [_ for _ in X_train.columns if X_train[_].dtype == 'float']\n        scaler = StandardScaler()\n        X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n        X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n\n        return X_train, X_test\n    \n    def create_numeric_combinations(self, df):\n        new_cols = []\n        for comb in range(2, len(self.numeric_columns) + 1):\n            for col in combinations(self.numeric_columns, comb):\n                if len(col) > self.max_pattern:\n                    break\n                col_names = list(col)\n                new_col = '_'.join(col_names) + '_mult'\n                df[new_col] = df[col_names[0]]\n                for c in col_names[1:]:\n                    df[new_col] *= df[c]\n                new_cols.append(new_col)\n\n        return df\n\nnumeric_columns = [_ for _ in test.columns if 'is_generated' not in _]\npp = Preprocessor(numeric_columns)\nX, test = pp.preprocess(X, test)\nprint(f\"X_train shape :{X.shape}\", f\"X_test shape :{test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-18T07:54:22.543148Z","iopub.execute_input":"2023-03-18T07:54:22.543704Z","iopub.status.idle":"2023-03-18T07:54:22.885684Z","shell.execute_reply.started":"2023-03-18T07:54:22.543653Z","shell.execute_reply":"2023-03-18T07:54:22.884219Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"X_train shape :(117564, 36) X_test shape :(78377, 36)\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\n\nimport optuna\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import log_loss\n\nlgb_params = {\n    'n_estimators': 150,\n    'max_depth': 3,\n    'learning_rate': 0.19503709130426908,\n    'subsample': 0.016314517193550798,\n    'colsample_bytree': 0.4430207740011624,\n    'reg_alpha': 2.3355195856646724e-06,\n    'reg_lambda': 0.6375339245312847,\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'boosting_type': 'gbdt',\n    'random_state': 3407\n}\n\nf_imp = pd.DataFrame({'feature': X.columns})\nFOLDS = 10\nseed = 3407\nbold = ['\\033[1m', '\\033[0m']\ntemp_pred = []\ntemp_y = []\nlogs = [] \ncv_scores = []\npredictions =[] \nk = KFold(n_splits=FOLDS, random_state=seed, shuffle=True)\nfor fold, (train_idx, val_idx) in enumerate(k.split(X, y)):\n    print(f'\\n--- FOLD {fold+1} ---')\n    model = lgb.LGBMClassifier(**lgb_params)\n    model = model.fit(X.iloc[train_idx],y.iloc[train_idx])\n    x_test,y_test = X.iloc[val_idx],y.iloc[val_idx]\n    fold_xt_pred = model.predict_proba(x_test)[:,1]\n    fold_test_pred = model.predict_proba(test)[:,1]\n    temp_pred.append(fold_xt_pred)\n    temp_y.append(y_test)\n    logs.append(log_loss(y_test,fold_xt_pred))\n    print(\"--------------\", log_loss(y_test,fold_xt_pred))\n    predictions.append(fold_test_pred)\n    cv_scores.append(np.mean(logs))\nlgbm_cv_score = np.mean(cv_scores)\nprint('LGBM CV SCORE : ', lgbm_cv_score)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:16:51.464514Z","iopub.execute_input":"2023-03-18T08:16:51.465304Z","iopub.status.idle":"2023-03-18T08:17:01.287268Z","shell.execute_reply.started":"2023-03-18T08:16:51.465262Z","shell.execute_reply":"2023-03-18T08:17:01.286043Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"\n--- FOLD 1 ---\n-------------- 0.029738930568252466\n\n--- FOLD 2 ---\n-------------- 0.03465466131317763\n\n--- FOLD 3 ---\n-------------- 0.032220371827969684\n\n--- FOLD 4 ---\n-------------- 0.0357303584690915\n\n--- FOLD 5 ---\n-------------- 0.02814698066349476\n\n--- FOLD 6 ---\n-------------- 0.02778833055715742\n\n--- FOLD 7 ---\n-------------- 0.029230339971668472\n\n--- FOLD 8 ---\n-------------- 0.030885164512316286\n\n--- FOLD 9 ---\n-------------- 0.03386165016802756\n\n--- FOLD 10 ---\n-------------- 0.030494838469644032\nLGBM CV SCORE :  0.03154639346568204\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.isotonic import IsotonicRegression\ndef iso_calib(valid_predictions,valid_target,test_pred):   \n    isotonic_reg = IsotonicRegression(out_of_bounds='clip')\n    isotonic_reg.fit(valid_predictions,valid_target)\n    isotonic_pred_caliberated = isotonic_reg.predict(test_pred)\n    return isotonic_pred_caliberated","metadata":{"execution":{"iopub.status.busy":"2023-03-18T07:51:11.716858Z","iopub.execute_input":"2023-03-18T07:51:11.717601Z","iopub.status.idle":"2023-03-18T07:51:11.723713Z","shell.execute_reply.started":"2023-03-18T07:51:11.717539Z","shell.execute_reply":"2023-03-18T07:51:11.722332Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"lgbm_prediction = np.mean(predictions,axis=0)\n# caliberated_predictions = list()\n# for i in range(FOLDS):\n#     caliberated_predictions.append(iso_calib(temp_pred[i],temp_y[i],lgbm_prediction))\n# lgbm_pred_test = np.mean(caliberated_predictions,axis=0)\nlgbm_prediction","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:10:09.898886Z","iopub.execute_input":"2023-03-18T08:10:09.899321Z","iopub.status.idle":"2023-03-18T08:10:09.909456Z","shell.execute_reply.started":"2023-03-18T08:10:09.899283Z","shell.execute_reply":"2023-03-18T08:10:09.908051Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"array([3.03999909e-05, 1.62661084e-03, 4.08172523e-05, ...,\n       7.43001612e-05, 7.17676297e-02, 9.76153176e-01])"},"metadata":{}}]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:09:59.554053Z","iopub.execute_input":"2023-03-18T08:09:59.554622Z","iopub.status.idle":"2023-03-18T08:09:59.567883Z","shell.execute_reply.started":"2023-03-18T08:09:59.554570Z","shell.execute_reply":"2023-03-18T08:09:59.566288Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"[array([2.24037300e-05, 4.83338892e-04, 3.45209506e-05, ...,\n        6.33078336e-05, 7.69813631e-02, 9.71103753e-01]),\n array([2.04518749e-05, 2.23273104e-03, 4.15749072e-05, ...,\n        7.06551302e-05, 8.75789220e-02, 9.74203701e-01]),\n array([2.67536003e-05, 1.15366977e-03, 4.71352974e-05, ...,\n        6.29925468e-05, 6.72827768e-02, 9.62225805e-01]),\n array([1.79713748e-05, 1.87812231e-03, 2.64231712e-05, ...,\n        3.06837376e-05, 7.48136387e-02, 9.83999044e-01]),\n array([2.35229316e-05, 5.04682255e-04, 3.67686256e-05, ...,\n        8.52701307e-05, 9.65946636e-02, 9.74182961e-01]),\n array([4.73831261e-05, 2.07791690e-03, 2.82169831e-05, ...,\n        8.00140832e-05, 7.60668660e-02, 9.82773951e-01]),\n array([1.82300066e-05, 2.16972391e-03, 4.78697118e-05, ...,\n        8.43211683e-05, 5.83614087e-02, 9.85187872e-01]),\n array([1.96227656e-05, 1.49930406e-03, 3.03494742e-05, ...,\n        7.60731610e-05, 9.06179450e-02, 9.71915243e-01]),\n array([8.62008823e-05, 1.49802606e-03, 5.92502765e-05, ...,\n        1.01904634e-04, 4.83902313e-02, 9.81891921e-01]),\n array([2.14596165e-05, 2.76859325e-03, 5.60631253e-05, ...,\n        8.77791870e-05, 4.09884818e-02, 9.74047506e-01])]"},"metadata":{}}]},{"cell_type":"code","source":"ans_lgb = pd.read_csv(\"/kaggle/input/playground-series-s3e10/sample_submission.csv\")\nans_lgb[\"Class\"] = lgbm_prediction #np.where(predictions>0.5, 1, 0)\nans_lgb.to_csv(\"ans_lgb.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:10:15.958987Z","iopub.execute_input":"2023-03-18T08:10:15.959729Z","iopub.status.idle":"2023-03-18T08:10:16.171679Z","shell.execute_reply.started":"2023-03-18T08:10:15.959688Z","shell.execute_reply":"2023-03-18T08:10:16.170785Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:10:19.823811Z","iopub.execute_input":"2023-03-18T08:10:19.824214Z","iopub.status.idle":"2023-03-18T08:10:20.031667Z","shell.execute_reply.started":"2023-03-18T08:10:19.824179Z","shell.execute_reply":"2023-03-18T08:10:20.030730Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"ans_lgb","metadata":{"execution":{"iopub.status.busy":"2023-03-18T08:05:54.161248Z","iopub.execute_input":"2023-03-18T08:05:54.162019Z","iopub.status.idle":"2023-03-18T08:05:54.174680Z","shell.execute_reply.started":"2023-03-18T08:05:54.161969Z","shell.execute_reply":"2023-03-18T08:05:54.173403Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"           id     Class\n0      117564  0.000108\n1      117565  0.000765\n2      117566  0.000120\n3      117567  0.048380\n4      117568  0.001903\n...       ...       ...\n78372  195936  0.000236\n78373  195937  0.000162\n78374  195938  0.000159\n78375  195939  0.069267\n78376  195940  0.977271\n\n[78377 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>117564</td>\n      <td>0.000108</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>117565</td>\n      <td>0.000765</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>117566</td>\n      <td>0.000120</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>117567</td>\n      <td>0.048380</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>117568</td>\n      <td>0.001903</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>78372</th>\n      <td>195936</td>\n      <td>0.000236</td>\n    </tr>\n    <tr>\n      <th>78373</th>\n      <td>195937</td>\n      <td>0.000162</td>\n    </tr>\n    <tr>\n      <th>78374</th>\n      <td>195938</td>\n      <td>0.000159</td>\n    </tr>\n    <tr>\n      <th>78375</th>\n      <td>195939</td>\n      <td>0.069267</td>\n    </tr>\n    <tr>\n      <th>78376</th>\n      <td>195940</td>\n      <td>0.977271</td>\n    </tr>\n  </tbody>\n</table>\n<p>78377 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]}]}