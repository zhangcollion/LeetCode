{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-22T07:33:38.745857Z","iopub.execute_input":"2022-05-22T07:33:38.746196Z","iopub.status.idle":"2022-05-22T07:33:38.770470Z","shell.execute_reply.started":"2022-05-22T07:33:38.746109Z","shell.execute_reply":"2022-05-22T07:33:38.769696Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!conda install -y gdown\n!gdown --id '15XWO-zI-AKW0igfwSydmwSGa8ENb9wCg' --output data-bin.tar.gz \n!tar zxvf data-bin.tar.gz\n!ls data-bin\n!rm data-bin.tar.gz","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:33:51.215574Z","iopub.execute_input":"2022-05-22T07:33:51.215846Z","iopub.status.idle":"2022-05-22T07:35:24.868772Z","shell.execute_reply.started":"2022-05-22T07:33:51.215812Z","shell.execute_reply":"2022-05-22T07:35:24.867594Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"## data process\nimport numpy as np\nimport random\nimport torch\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n                              TensorDataset,Dataset)\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:33:48.838536Z","iopub.execute_input":"2022-05-22T07:33:48.838805Z","iopub.status.idle":"2022-05-22T07:33:50.789104Z","shell.execute_reply.started":"2022-05-22T07:33:48.838775Z","shell.execute_reply":"2022-05-22T07:33:50.787986Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = np.load('data-bin/trainingset.npy', allow_pickle=True)\ntest = np.load('data-bin/testingset.npy', allow_pickle=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:35:50.773994Z","iopub.execute_input":"2022-05-22T07:35:50.774853Z","iopub.status.idle":"2022-05-22T07:35:51.456570Z","shell.execute_reply.started":"2022-05-22T07:35:50.774797Z","shell.execute_reply":"2022-05-22T07:35:51.455747Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## data process\nimport numpy as np\nimport random\nimport torch\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n                              TensorDataset,Dataset)\n\nimport torchvision.transforms as transforms\n# class VAEDataset(TensorDataset):\nclass VAEDataset(Dataset):\n    def __init__(self, data_tensor):\n        self.data = data_tensor\n        self.transfomer = transforms.Compose([\n                            transforms.Lambda(lambda x: x.to(torch.float32)),\n                            transforms.Lambda(lambda x: 2. * x/255. - 1.),\n                            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n                            ])\n        self.data = torch.FloatTensor(self.data)\n        if self.data.shape[-1] == 3:\n             self.data = self.data.permute(0,3,1,2) # [sample, 3,64,64]\n        \n    def __getitem__(self, index):\n        x = self.data[index]\n        if self.transfomer:\n            x = self.transfomer(x)\n        return x\n        \n    def __len__(self):\n        return len(self.data)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-22T04:19:12.31866Z","iopub.execute_input":"2022-05-22T04:19:12.318933Z","iopub.status.idle":"2022-05-22T04:19:14.506904Z","shell.execute_reply.started":"2022-05-22T04:19:12.318903Z","shell.execute_reply":"2022-05-22T04:19:14.505642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomTensorDataset(TensorDataset):\n    \"\"\"TensorDataset with support of transforms.\n    \"\"\"\n    def __init__(self, tensors):\n        self.tensors = tensors\n        if tensors.shape[-1] == 3:\n            self.tensors = tensors.permute(0, 3, 1, 2)\n        \n        self.transform = transforms.Compose([\n                            transforms.Lambda(lambda x: x.to(torch.float32)),\n                            transforms.Lambda(lambda x: 2. * x/255. - 1.),\n                            # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n                            ])\n        \n    def __getitem__(self, index):\n        x = self.tensors[index]\n        \n        if self.transform:\n            # mapping images to [-1.0, 1.0]\n            x = self.transform(x)\n\n        return x\n\n    def __len__(self):\n        return len(self.tensors)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:35:55.790801Z","iopub.execute_input":"2022-05-22T07:35:55.791065Z","iopub.status.idle":"2022-05-22T07:35:55.799424Z","shell.execute_reply.started":"2022-05-22T07:35:55.791036Z","shell.execute_reply":"2022-05-22T07:35:55.798424Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## dataloader\nx = torch.from_numpy(train)\nbatch_size = 256\ntrain_dataset = CustomTensorDataset(x)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:35:58.447385Z","iopub.execute_input":"2022-05-22T07:35:58.447641Z","iopub.status.idle":"2022-05-22T07:35:58.454524Z","shell.execute_reply.started":"2022-05-22T07:35:58.447612Z","shell.execute_reply":"2022-05-22T07:35:58.453764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torch.autograd import Variable\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3,12,4,stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(12,24,4,stride=2,padding=1),\n            nn.ReLU(),\n        )\n        self.enc_out_1 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),  \n            nn.ReLU(),\n        )\n        self.enc_out_2 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1), \n            nn.Tanh(),\n        )\n        \n    def encode(self, x):\n        h1 = self.encoder(x)\n        return self.enc_out_1(h1), self.enc_out_2(h1)\n    \n    def reparameterize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n    \n    def decode(self, z):\n        return self.decoder(z)\n        \n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        return self.decode(z), mu, logvar","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:36:02.339804Z","iopub.execute_input":"2022-05-22T07:36:02.340139Z","iopub.status.idle":"2022-05-22T07:36:02.363616Z","shell.execute_reply.started":"2022-05-22T07:36:02.340101Z","shell.execute_reply":"2022-05-22T07:36:02.362849Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def loss_vae(recon_x, x, mu, logvar, criterion):\n    mse = criterion(recon_x, x)\n    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_element).mul_(-0.5)\n    return mse + KLD","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:36:05.347740Z","iopub.execute_input":"2022-05-22T07:36:05.347999Z","iopub.status.idle":"2022-05-22T07:36:05.353557Z","shell.execute_reply.started":"2022-05-22T07:36:05.347970Z","shell.execute_reply":"2022-05-22T07:36:05.352632Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer\n# model = VAE()\nmodel = conv_autoencoder()\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(\n    model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:16:31.977257Z","iopub.execute_input":"2022-05-22T08:16:31.977539Z","iopub.status.idle":"2022-05-22T08:16:31.987401Z","shell.execute_reply.started":"2022-05-22T08:16:31.977507Z","shell.execute_reply":"2022-05-22T08:16:31.986609Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:36:52.050139Z","iopub.execute_input":"2022-05-22T07:36:52.050664Z","iopub.status.idle":"2022-05-22T07:36:52.082731Z","shell.execute_reply.started":"2022-05-22T07:36:52.050619Z","shell.execute_reply":"2022-05-22T07:36:52.082018Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"ans_loss = []\nimport time\nfor epoch in range(30):\n    tmp_loss = []\n    start = int(time.time())\n    for ele_data in train_dataloader:\n        ele_data = ele_data.to(device)\n        model = model.to(device)\n#         y_pred, mu, logvar = model(ele_data)\n        y_pred  = model(ele_data)\n        optimizer.zero_grad()\n#         ele_loss = loss_vae(y_pred,ele_data,mu, logvar,criterion)\n        ele_loss =  criterion(y_pred,ele_data)\n        ele_loss.backward()\n        optimizer.step()\n#         tmp_loss.append(ele_loss.item())\n        tmp_loss.append(ele_loss.item())\n    print(f\"{epoch} epoch loss is {np.mean(tmp_loss)} cost time {int(time.time())-start}\")\n    ans_loss.append(np.mean(tmp_loss))","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:18:05.963978Z","iopub.execute_input":"2022-05-22T08:18:05.964588Z","iopub.status.idle":"2022-05-22T08:28:35.403536Z","shell.execute_reply.started":"2022-05-22T08:18:05.964547Z","shell.execute_reply":"2022-05-22T08:28:35.402779Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"x = torch.from_numpy(test)\nbatch_size = 1\ntest_dataset = CustomTensorDataset(x)\ntest_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T07:48:01.382723Z","iopub.execute_input":"2022-05-22T07:48:01.382980Z","iopub.status.idle":"2022-05-22T07:48:01.388482Z","shell.execute_reply.started":"2022-05-22T07:48:01.382950Z","shell.execute_reply":"2022-05-22T07:48:01.387771Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tmp_loss = []\neval_loss = nn.MSELoss()\nmodel.eval()\nfor ele_data in test_dataloader:\n    ele_data = ele_data.to(device)\n#     y_pred, mu, logvar = model(ele_data)\n    y_pred  = model(ele_data)\n    ele_loss = eval_loss(y_pred,ele_data)\n    tmp_loss.append(ele_loss.item())\nprint(f\"{epoch} epoch loss is {np.mean(tmp_loss)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:32:01.127784Z","iopub.execute_input":"2022-05-22T08:32:01.128042Z","iopub.status.idle":"2022-05-22T08:32:28.248814Z","shell.execute_reply.started":"2022-05-22T08:32:01.128010Z","shell.execute_reply":"2022-05-22T08:32:28.248080Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"tmp2_loss = []\nmodel.eval()\nfor ele_data in train_dataloader:\n    y_pred, mu, logvar = model(ele_data)\n    ele_loss = loss_vae(y_pred,ele_data,mu, logvar,criterion)\n    tmp2_loss.append(ele_loss.data.numpy())\nprint(f\"{epoch} epoch loss is {np.mean(tmp2_loss)}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T06:59:12.50429Z","iopub.execute_input":"2022-05-22T06:59:12.504596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot((tmp_loss), \"r\", label=\"val_loss\")\n# plt.plot(tmp2_loss, 'g', label=\"train_loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:34:19.464909Z","iopub.execute_input":"2022-05-22T08:34:19.465181Z","iopub.status.idle":"2022-05-22T08:34:19.727557Z","shell.execute_reply.started":"2022-05-22T08:34:19.465149Z","shell.execute_reply":"2022-05-22T08:34:19.726894Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"x = torch.from_numpy(train)\nbatch_size = 1\ntrain_dataset = CustomTensorDataset(x)\ntrain_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T06:59:08.310752Z","iopub.execute_input":"2022-05-22T06:59:08.31163Z","iopub.status.idle":"2022-05-22T06:59:08.317427Z","shell.execute_reply.started":"2022-05-22T06:59:08.311561Z","shell.execute_reply":"2022-05-22T06:59:08.316527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = np.quantile(tmp_loss,0.76)\nthreshold","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:34:39.312684Z","iopub.execute_input":"2022-05-22T08:34:39.312949Z","iopub.status.idle":"2022-05-22T08:34:39.322631Z","shell.execute_reply.started":"2022-05-22T08:34:39.312919Z","shell.execute_reply":"2022-05-22T08:34:39.321780Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"ans = np.where(tmp_loss> threshold, 0, 1)\n# data = pd.read_csv(\"/kaggle/input/ml2021spring-hw8/sample.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:34:42.075955Z","iopub.execute_input":"2022-05-22T08:34:42.076471Z","iopub.status.idle":"2022-05-22T08:34:42.087159Z","shell.execute_reply.started":"2022-05-22T08:34:42.076420Z","shell.execute_reply":"2022-05-22T08:34:42.086140Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"data[\"Predicted\"] = ans\ndata.to_csv(\"sample12.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:34:45.452363Z","iopub.execute_input":"2022-05-22T08:34:45.452625Z","iopub.status.idle":"2022-05-22T08:34:45.486106Z","shell.execute_reply.started":"2022-05-22T08:34:45.452594Z","shell.execute_reply":"2022-05-22T08:34:45.485408Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"## other model\n\nclass fcn_autoencoder(nn.Module):\n    def __init__(self):\n        super(fcn_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(64 * 64 * 3, 128),\n            nn.ReLU(True),\n            nn.Linear(128, 64),\n            nn.ReLU(True), \n            nn.Linear(64, 12), \n            nn.ReLU(True), \n            nn.Linear(12, 3))\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(3, 12),\n            nn.ReLU(True),\n            nn.Linear(12, 64),\n            nn.ReLU(True),\n            nn.Linear(64, 128),\n            nn.ReLU(True), \n            nn.Linear(128, 64 * 64 * 3), \n            nn.Tanh())\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n    \nclass conv_autoencoder(nn.Module):\n    def __init__(self):\n        super(conv_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),         \n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),        \n            nn.ReLU(),\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),         \n            nn.ReLU(),\n            nn.Conv2d(48, 96, 4, stride=2, padding=1),   # medium: remove this layer\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1), # medium: remove this layer\n            nn.ReLU(),\n            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-05-22T08:14:59.615625Z","iopub.execute_input":"2022-05-22T08:14:59.616095Z","iopub.status.idle":"2022-05-22T08:14:59.630065Z","shell.execute_reply.started":"2022-05-22T08:14:59.616045Z","shell.execute_reply":"2022-05-22T08:14:59.628998Z"},"trusted":true},"execution_count":53,"outputs":[]}]}