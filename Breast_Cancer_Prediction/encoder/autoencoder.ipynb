{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(tf.keras.Model):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.coder_out = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.coder_out)\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(self.out_dim )\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        coder_in = self.encoder(x)\n",
    "        coder_out = self.decoder(coder_in)\n",
    "        return coder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder(3, 256)\n",
    "encoder.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'zeros'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Applies a 2D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
       "can be precisely described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
       "    \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
       "\n",
       "\n",
       "where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`H` is a height of input planes in pixels, and :math:`W` is\n",
       "width in pixels.\n",
       "\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit padding on both\n",
       "  sides for :attr:`padding` number of points for each dimension.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters (of size\n",
       "      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
       "\n",
       "The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
       "\n",
       "    - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
       "    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
       "      and the second `int` for the width dimension\n",
       "\n",
       "Note:\n",
       "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
       "    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
       "\n",
       "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
       "    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
       "    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
       "\n",
       "Note:\n",
       "    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of\n",
       "        the input. Default: 0\n",
       "    padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n",
       "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
       "    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
       "        output. Default: ``True``\n",
       "\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
       "    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
       "                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
       "\n",
       "      .. math::\n",
       "          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
       "                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
       "        :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
       "        The values of these weights are sampled from\n",
       "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels). If :attr:`bias` is ``True``,\n",
       "        then the values of these weights are\n",
       "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> # With square kernels and equal stride\n",
       "    >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
       "    >>> # non-square kernels and unequal stride and with padding\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
       "    >>> # non-square kernels and unequal stride and with padding and dilation\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
       "    >>> input = torch.randn(20, 16, 50, 100)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[1;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\programdata\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Conv2d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "2D convolution layer (e.g. spatial convolution over images).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input to produce a tensor of\n",
       "outputs. If `use_bias` is True,\n",
       "a bias vector is created and added to the outputs. Finally, if\n",
       "`activation` is not `None`, it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide the keyword argument `input_shape`\n",
       "(tuple of integers or `None`, does not include the sample axis),\n",
       "e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
       "in `data_format=\"channels_last\"`. You can use `None` when\n",
       "a dimension has variable size.\n",
       "\n",
       "Examples:\n",
       "\n",
       ">>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n",
       ">>> # size is 4.\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 26, 26, 2)\n",
       "\n",
       ">>> # With `dilation_rate` as 2.\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 24, 24, 2)\n",
       "\n",
       ">>> # With `padding` as \"same\".\n",
       ">>> input_shape = (4, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 28, 28, 2)\n",
       "\n",
       ">>> # With extended batch shape [4, 7]:\n",
       ">>> input_shape = (4, 7, 28, 28, 3)\n",
       ">>> x = tf.random.normal(input_shape)\n",
       ">>> y = tf.keras.layers.Conv2D(\n",
       "... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
       ">>> print(y.shape)\n",
       "(4, 7, 26, 26, 2)\n",
       "\n",
       "\n",
       "Args:\n",
       "  filters: Integer, the dimensionality of the output space (i.e. the number of\n",
       "    output filters in the convolution).\n",
       "  kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
       "    and width of the 2D convolution window. Can be a single integer to specify\n",
       "    the same value for all spatial dimensions.\n",
       "  strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
       "    the convolution along the height and width. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions. Specifying any stride\n",
       "    value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n",
       "  padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "    `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n",
       "    to the left/right or up/down of the input such that output has the same\n",
       "    height/width dimension as the input.\n",
       "  data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
       "    The ordering of the dimensions in the inputs. `channels_last` corresponds\n",
       "    to inputs with shape `(batch_size, height, width, channels)` while\n",
       "    `channels_first` corresponds to inputs with shape `(batch_size, channels,\n",
       "    height, width)`. It defaults to the `image_data_format` value found in\n",
       "    your Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
       "    it will be `channels_last`.\n",
       "  dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
       "    dilation rate to use for dilated convolution. Can be a single integer to\n",
       "    specify the same value for all spatial dimensions. Currently, specifying\n",
       "    any `dilation_rate` value != 1 is incompatible with specifying any stride\n",
       "    value != 1.\n",
       "  groups: A positive integer specifying the number of groups in which the\n",
       "    input is split along the channel axis. Each group is convolved separately\n",
       "    with `filters / groups` filters. The output is the concatenation of all\n",
       "    the `groups` results along the channel axis. Input channels and `filters`\n",
       "    must both be divisible by `groups`.\n",
       "  activation: Activation function to use. If you don't specify anything, no\n",
       "    activation is applied (see `keras.activations`).\n",
       "  use_bias: Boolean, whether the layer uses a bias vector.\n",
       "  kernel_initializer: Initializer for the `kernel` weights matrix (see\n",
       "    `keras.initializers`). Defaults to 'glorot_uniform'.\n",
       "  bias_initializer: Initializer for the bias vector (see\n",
       "    `keras.initializers`). Defaults to 'zeros'.\n",
       "  kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
       "    matrix (see `keras.regularizers`). \n",
       "  bias_regularizer: Regularizer function applied to the bias vector (see\n",
       "    `keras.regularizers`). \n",
       "  activity_regularizer: Regularizer function applied to the output of the\n",
       "    layer (its \"activation\") (see `keras.regularizers`).\n",
       "  kernel_constraint: Constraint function applied to the kernel matrix (see\n",
       "    `keras.constraints`).\n",
       "  bias_constraint: Constraint function applied to the bias vector (see\n",
       "    `keras.constraints`).\n",
       "Input shape:\n",
       "  4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n",
       "    `data_format='channels_first'`\n",
       "  or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n",
       "    `data_format='channels_last'`.\n",
       "Output shape:\n",
       "  4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n",
       "  `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n",
       "    (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n",
       "    and `cols` values might have changed due to padding.\n",
       "\n",
       "Returns:\n",
       "  A tensor of rank 4+ representing\n",
       "  `activation(conv2d(inputs, kernel) + bias)`.\n",
       "\n",
       "Raises:\n",
       "  ValueError: if `padding` is `\"causal\"`.\n",
       "  ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\programdata\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
